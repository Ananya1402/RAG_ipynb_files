{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "#VSC-4139415f",
            "metadata": {
                "language": "markdown"
            },
            "source": [
                "# Basic RAG pipeline\n",
                "Vector DB - Chroma DB\n",
                "\n",
                "Embeddings Model - Sentence Transformers - all-mpnet-base-v2\n",
                "\n",
                "Loaders to load External Data\n",
                "\n",
                "LLM Integration to generate final response using user query along with retrieved chunks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "#VSC-d25d30d0",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "source": [
                "# installations\n",
                "%pip install langchain langchain-community chromadb langchain-huggingface protobuf langchain-google-genai BeautifulSoup4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "#VSC-fb07d0c7",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ['USER_AGENT'] = 'myagent'\n",
                "from langchain.document_loaders import WebBaseLoader\n",
                "URL = [\n",
                "    \"https://education.nationalgeographic.org/resource/global-warming/\",\n",
                "    \"https://en.wikipedia.org/wiki/Climate_change\",\n",
                "    \"https://www.nrdc.org/stories/global-warming-101\"\n",
                "]\n",
                "# load the data\n",
                "data = WebBaseLoader(URL)\n",
                "# extract the content\n",
                "content = data.load()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "#VSC-99afbe3d",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "source": [
                "# Chunking\n",
                "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=60)\n",
                "chunks = text_splitter.split_documents(content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "#VSC-f6efbfc6",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "source": [
                "len(chunks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "#VSC-8fa96b2b",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "source": [
                "# Downloading the embedding model\n",
                "from langchain_huggingface import HuggingFaceEmbeddings\n",
                "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "#VSC-8292297a",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "source": [
                "# Define the vector DB\n",
                "from langchain.vectorstores import Chroma\n",
                "vectorstore = Chroma.from_documents(chunks, embeddings)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "#VSC-ed7e6e4f",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "source": [
                "# Step 1: Retrieval\n",
                "query = \"What are the different causes of global warming?\"\n",
                "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":4})\n",
                "docs_retrieved = retriever.get_relevant_documents(query)\n",
                "print(docs_retrieved)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "#VSC-05fa33b8",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "source": [
                "# Creating LLM object\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "from google.colab import userdata\n",
                "GEMINI_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
                "llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash', api_key=GEMINI_API_KEY)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "#VSC-dbd19b59",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "source": [
                "# Augment\n",
                "query = 'What are the causes of global warming?'\n",
                "system_prompt = f\"\"\"\n",
                "You are an AI assistant that responds to a given user query. Please keep your answers relevant to the context you have.\n",
                "\n",
                "User Query: {query}\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "#VSC-0a510223",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "source": [
                "# Generation\n",
                "from langchain.chains import RetrievalQA\n",
                "qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")\n",
                "response = qa(system_prompt)\n",
                "print(response['result'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "#VSC-6b57ca3a",
            "metadata": {
                "language": "python"
            },
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
